{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K85JPbZxm1Hh",
        "outputId": "8860e02c-12e1-434c-d09b-5b82655c05d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Sun Dec  8 23:33:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import json\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "metadata": {
        "id": "_vytCqB5nC1L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=33):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "        def up_block(in_channels, out_channels):\n",
        "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "        self.encoder1 = conv_block(in_channels, 64)\n",
        "        self.encoder2 = conv_block(64, 128)\n",
        "        self.encoder3 = conv_block(128, 256)\n",
        "        self.encoder4 = conv_block(256, 512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = conv_block(512, 1024)\n",
        "\n",
        "        self.upconv4 = up_block(1024, 512)\n",
        "        self.decoder4 = conv_block(1024, 512)\n",
        "        self.upconv3 = up_block(512, 256)\n",
        "        self.decoder3 = conv_block(512, 256)\n",
        "        self.upconv2 = up_block(256, 128)\n",
        "        self.decoder2 = conv_block(256, 128)\n",
        "        self.upconv1 = up_block(128, 64)\n",
        "        self.decoder1 = conv_block(128, 64)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool(enc1))\n",
        "        enc3 = self.encoder3(self.pool(enc2))\n",
        "        enc4 = self.encoder4(self.pool(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = self.decoder4(torch.cat((dec4, enc4), dim=1))\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = self.decoder3(torch.cat((dec3, enc3), dim=1))\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = self.decoder2(torch.cat((dec2, enc2), dim=1))\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = self.decoder1(torch.cat((dec1, enc1), dim=1))\n",
        "\n",
        "        return self.final_conv(dec1)\n",
        "\n",
        "\n",
        "\n",
        "class ToothSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, coco_json, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(coco_json, \"r\") as f:\n",
        "            coco_data = json.load(f)\n",
        "\n",
        "        # Group annotations by image_id\n",
        "        self.image_info = {img[\"id\"]: img for img in coco_data[\"images\"]}\n",
        "        self.image_annotations = {img_id: [] for img_id in self.image_info.keys()}\n",
        "        for annotation in coco_data[\"annotations\"]:\n",
        "            self.image_annotations[annotation[\"image_id\"]].append(annotation)\n",
        "\n",
        "        # Use only image IDs for indexing\n",
        "        self.image_ids = list(self.image_info.keys())\n",
        "        print(f\"Dataset initialized with {len(self.image_ids)} images.\")\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # print(f\"getting item {index}\")\n",
        "        image_id = self.image_ids[index]\n",
        "        image_name = self.image_info[image_id][\"file_name\"]\n",
        "        image_path = os.path.join(self.image_dir, image_name)\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(image_path).convert(\"L\")  # Grayscale\n",
        "\n",
        "        # Create composite mask\n",
        "        mask = Image.new(\"L\", image.size, 0)  # Start with a blank mask\n",
        "        # mask = Image.new(\"L\", image.size, 32)  # Start with a blank mask\n",
        "        draw = ImageDraw.Draw(mask)\n",
        "        for annotation in self.image_annotations[image_id]:\n",
        "            points = np.array(annotation[\"segmentation\"]).reshape(-1, 2)\n",
        "            draw.polygon([tuple(p) for p in points], fill=annotation[\"category_id\"]+1)\n",
        "\n",
        "        if self.transform:\n",
        "            image, mask = self.transform(image, mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "\n",
        "def transform(image, mask):\n",
        "    image = TF.resize(image, (256, 256))\n",
        "    mask = TF.resize(mask, (256, 256), interpolation=Image.NEAREST)\n",
        "    image = TF.to_tensor(image)\n",
        "    mask = torch.from_numpy(np.array(mask, dtype=np.int64))  # Convert to tensor\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weights=None):\n",
        "        \"\"\"\n",
        "        DiceLoss with optional class weights.\n",
        "\n",
        "        Args:\n",
        "            weights (torch.Tensor): Weights for each class. Shape: (num_classes,)\n",
        "        \"\"\"\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.softmax(pred, dim=1)  # Class probabilities\n",
        "        target = F.one_hot(target, num_classes=33).permute(0, 3, 1, 2).float()  # One-hot encode target\n",
        "\n",
        "        intersection = (pred * target).sum(dim=(2, 3))  # Per class intersection\n",
        "        union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))  # Per class union\n",
        "\n",
        "        dice_score = 2.0 * intersection / (union + 1e-6)  # Per class Dice score\n",
        "\n",
        "        # Apply weights\n",
        "        if self.weights is not None:\n",
        "            dice_score = dice_score * self.weights.view(1, -1)\n",
        "\n",
        "        return 1.0 - dice_score.mean()  # Mean weighted Dice loss\n",
        "\n",
        "\n",
        "def dice_metric(pred, target, num_classes=33):\n",
        "    \"\"\"\n",
        "    Compute per-class Dice scores.\n",
        "    \"\"\"\n",
        "    pred = torch.argmax(pred, dim=1)  # Shape: (batch_size, H, W)\n",
        "    dice_scores = []\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        pred_c = (pred == c).float()\n",
        "        target_c = (target == c).float()\n",
        "\n",
        "        intersection = (pred_c * target_c).sum()\n",
        "        union = pred_c.sum() + target_c.sum()\n",
        "\n",
        "        if union == 0:  # Avoid NaN for empty classes\n",
        "            dice_scores.append(torch.tensor(1.0))  # Perfect score for empty classes\n",
        "        else:\n",
        "            dice_scores.append((2.0 * intersection) / (union + 1e-6))\n",
        "\n",
        "    return dice_scores\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_unet(model, train_loader, val_loader, epochs, device, weights):\n",
        "    model = model.to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "    # criterion = DiceLoss(weights=weights.to(device))\n",
        "\n",
        "    # Use CrossEntropyLoss with optional weights\n",
        "    if weights is not None:\n",
        "        weights = weights.to(device)\n",
        "        criterion = CrossEntropyLoss(weight=weights)\n",
        "    else:\n",
        "        criterion = CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for images, masks in train_loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            all_dice_scores = {c: [] for c in range(33)}\n",
        "            for images, masks in val_loader:\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                outputs = model(images)\n",
        "                per_class_dice = dice_metric(outputs, masks)\n",
        "                for c, score in enumerate(per_class_dice):\n",
        "                    all_dice_scores[c].append(score)\n",
        "\n",
        "        mean_dice_scores = {c: sum(scores) / len(scores) for c, scores in all_dice_scores.items()}\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Per-Class Dice Scores: {mean_dice_scores}\")\n",
        "        overall_dice = sum(mean_dice_scores.values()) / len(mean_dice_scores)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Overall Val Dice Score: {overall_dice:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "40V1yFbqnDDb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "base_dir = \"drive/MyDrive/training_data/quadrant_enumeration\"\n",
        "image_dir = os.path.join(base_dir, \"xrays_2048_1024\")\n",
        "mask_dir = os.path.join(base_dir, \"masks_teeth_2048_1024\")\n",
        "coco_json = os.path.join(base_dir, \"coco_quadrant_enumeration_2048_1024.json\")\n",
        "\n",
        "\n",
        "model_name = \"test_unet.pth\"\n",
        "\n",
        "\n",
        "\n",
        "# Hard-coded weights\n",
        "num_classes = 33\n",
        "background_proportion = 0.9\n",
        "tooth_proportion = 0.1 / 32  # Each of the 32 classes share 10%\n",
        "\n",
        "# Compute weights\n",
        "weights = [1 / tooth_proportion] * 32  # Equal weight for all 32 classes\n",
        "weights.append(1 / background_proportion)  # Weight for background class\n",
        "\n",
        "# Normalize weights\n",
        "weights = torch.tensor(weights, dtype=torch.float32)\n",
        "weights /= weights.sum()  # Normalize so weights sum to ~1\n",
        "\n",
        "# Print weights for reference\n",
        "print(\"Class Weights:\", weights)\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset = ToothSegmentationDataset(image_dir, mask_dir, coco_json, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Model, Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device is {device}\")\n",
        "model = UNet(in_channels=1, out_channels=33)\n",
        "\n",
        "\n",
        "epochs = 2\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U34H5sEqoET-",
        "outputId": "5eea961a-4a35-4533-c89b-14ce797d2e3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: tensor([0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
            "        0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
            "        0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
            "        0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0001])\n",
            "Dataset initialized with 634 images.\n",
            "Train dataset size: 507\n",
            "Validation dataset size: 127\n",
            "device is cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_unet(model, train_loader, val_loader, epochs=epochs, device=device, weights=weights)\n",
        "\n",
        "model_save_path = f\"drive/MyDrive/training_data/quadrant_enumeration/{model_name}\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDL6FSLvoVcb",
        "outputId": "7f4b19fc-6259-4c08-d8bb-470cde6bca01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Train Loss: 3.4596\n",
            "Epoch 1/2, Per-Class Dice Scores: {0: tensor(0.0196, device='cuda:0'), 1: tensor(0., device='cuda:0'), 2: tensor(0., device='cuda:0'), 3: tensor(0., device='cuda:0'), 4: tensor(0., device='cuda:0'), 5: tensor(0., device='cuda:0'), 6: tensor(0., device='cuda:0'), 7: tensor(0., device='cuda:0'), 8: tensor(0.0209, device='cuda:0'), 9: tensor(0., device='cuda:0'), 10: tensor(0., device='cuda:0'), 11: tensor(0., device='cuda:0'), 12: tensor(0., device='cuda:0'), 13: tensor(0.0073, device='cuda:0'), 14: tensor(0.0330, device='cuda:0'), 15: tensor(0., device='cuda:0'), 16: tensor(0., device='cuda:0'), 17: tensor(0., device='cuda:0'), 18: tensor(0.0182, device='cuda:0'), 19: tensor(0., device='cuda:0'), 20: tensor(0., device='cuda:0'), 21: tensor(0., device='cuda:0'), 22: tensor(0.0356, device='cuda:0'), 23: tensor(0.0312, device='cuda:0'), 24: tensor(0., device='cuda:0'), 25: tensor(0., device='cuda:0'), 26: tensor(0., device='cuda:0'), 27: tensor(0., device='cuda:0'), 28: tensor(0., device='cuda:0'), 29: tensor(0.0200, device='cuda:0'), 30: tensor(0.0354, device='cuda:0'), 31: tensor(0., device='cuda:0'), 32: tensor(0.2433, device='cuda:0')}\n",
            "Epoch 1/2, Overall Val Dice Score: 0.0141\n",
            "Epoch 2/2, Train Loss: 3.3678\n",
            "Epoch 2/2, Per-Class Dice Scores: {0: tensor(0.0091, device='cuda:0'), 1: tensor(0., device='cuda:0'), 2: tensor(0., device='cuda:0'), 3: tensor(0., device='cuda:0'), 4: tensor(0., device='cuda:0'), 5: tensor(4.0863e-05, device='cuda:0'), 6: tensor(0., device='cuda:0'), 7: tensor(0., device='cuda:0'), 8: tensor(0.0225, device='cuda:0'), 9: tensor(0.0028, device='cuda:0'), 10: tensor(0.0003, device='cuda:0'), 11: tensor(0., device='cuda:0'), 12: tensor(0., device='cuda:0'), 13: tensor(0., device='cuda:0'), 14: tensor(0.0273, device='cuda:0'), 15: tensor(0., device='cuda:0'), 16: tensor(0., device='cuda:0'), 17: tensor(0., device='cuda:0'), 18: tensor(0.0219, device='cuda:0'), 19: tensor(0.0175, device='cuda:0'), 20: tensor(0., device='cuda:0'), 21: tensor(0.0312, device='cuda:0'), 22: tensor(0.0347, device='cuda:0'), 23: tensor(0.0312, device='cuda:0'), 24: tensor(0., device='cuda:0'), 25: tensor(0., device='cuda:0'), 26: tensor(0., device='cuda:0'), 27: tensor(0., device='cuda:0'), 28: tensor(0., device='cuda:0'), 29: tensor(0.0077, device='cuda:0'), 30: tensor(0.0220, device='cuda:0'), 31: tensor(0., device='cuda:0'), 32: tensor(0.1993, device='cuda:0')}\n",
            "Epoch 2/2, Overall Val Dice Score: 0.0130\n",
            "Model saved to drive/MyDrive/training_data/quadrant_enumeration/test_unet.pth\n"
          ]
        }
      ]
    }
  ]
}